---
layout: post
title:  分布式事务及七种解决方案
date:   2024-08-22 22:02:22
categories: 分布式
tags: 分布式事务
---

* content
{:toc}


## 1. CAP 定理

- 一致性（C，Consistency）：数据在任何时刻、任何分布式节点中所看到的都是符合预期的

- 可用性（A，Availability）：系统能够不间断地提供服务。衡量指标为：可靠性和可维护性。可用性用于衡量系统可以正常使用的时间与总时间之比，即A = MTBF/(MTBF + MTTR)。MTBF 表示平均无故障时间，用于衡量可靠性；MTTR 表示平均可修复时间，用于衡量可维护性。

- 分区容忍性（P，Partition Tolerance）：即使在网络分区时，系统仍能正确地提供服务。

CAP 不可兼得，最多取其二，这是由于分布式环境下对网络的依赖，而网络不总是可靠的。但是由于 P 天然是不可舍弃的，所以 CAP 不可兼得也可以引申为 CA 不可兼得。

- 舍弃 P 而取 CA：这种情况意味着我们能够承诺网络通信永远是可靠的，不会产生分区现象。但这是不可能的，分布式环境下永远可靠的网络是不存在的。强行采用 CA 后果就是，在网络出现分区时系统将不能对外提供服务，只有这样才能保证 C，但是最终的结果是只能保证 C，却失了 AP。现实中虽然存在 CA 的服务，但是其 A 的保证却不依赖于网络，而是使用了共享同一份数据的方式。因此，也可以说 P 是不可放弃的。

- 舍弃 A 而取 CP：这也叫做“强一致性”。在网络出现分区时，节点之间信息的同步时间可能会被无限地延长，为了保证 C，需要在网络出现分区时暂停对外提供服务，从而确保各节点返回的数据总是一致的。但是暂停的时间是不确定的，因此 CP 适于对数据有高质量要求的场景。

- 舍弃 C 而取 AP：也叫“弱一致性”。在网络出现分区时，系统仍正常对外提供服务，但是节点在一段时间内可能会出现数据不一致。即使数据最后总会在某个时刻达到一致，但数据不一致的状态却是能够被感知到的。因此，对于对于银行、证券这些涉及金钱交易对数据有高质量的场景 AP 是不适用的。但是在大部分情况下我们总是能够容忍数据暂时的不一致，只要求数据在最后能够保证一致即可，所以 AP 往往是用的最多的，选择 A 往往契合于我们选择分布式的目的，不会出现随着节点的增加反而导致可用性的降低。



## 2. BASE 理论

BASE 理论是对 CA 不可兼得的调和剂，核心思想是即使无法做到强一致性，但是应用可以根据自身的业务特点采用适当的方式使系统达到最终一致性。我理解的 BASE 理论是，BASE 理论就是对 AP 的具体实施的理论指导却又不同于 AP，因为 BASE 理论也强调可以适当牺牲部分的可用性。说到底 BASE 理论是对 C 和 A 的权衡，若 C 的权占比越小那么 BASE 也就越趋向于 AP。

我们要实现一个 AP 系统时，往往需要对 C 和 A 做出权衡，所以我们常说的 AP 系统，可能就是 BASE。

- 基本可用（BA，Basically Available）：在分布式系统中出现不可预知的故障时，允许适当地损失部分可用性（在 BASE 中不是一定会牺牲可用性，只是允许而不是必须），只对外提供基本可用即可，即使这样会有部分的性能甚至功能上的损失。

- 软状态（S，Soft State）：允许系统中的数据存在中间状态，且可以被观察到，但是这种状态不会对系统整体的可用性产生影响但我们只要保证这种中间状态最终会过渡到一致性状态即可。

- 最终一致性（E，Eventually Consistent）：最终一致性强调的是系统所有的数据副本，在经过一段时间的同步后，最终能够达到一个一致的状态。因此，最终一致性的本质是需要系统保证最终数据能够达到一致，而不需要时时保证系统各节点数据的强一致性。

最终一致性的主要五个变种：

1. 因果一致性（Causal consistency）：如果进程A在更新完某个数据项后通知了进程B，那么进程B之后对数据项的访问都应该能够或得到进程A更新后的最新值，并且如果进程B要对改数据项进行更新操作的话，务必基于进程A更新后的最新值，即不能发生丢失更新情况。与此同时，与进程A无因果关系的进程C的数据访问则没有这样的显示。

2. 读己之所写（Read your write）：指进程A更新一个数据项之后，它自己总是能够访问到更新过的最新值，而不会看到旧值。也就是说，对于单个数据获取者来说，其读取到的数据，一定不会比自己上次写入的值旧。因此读己之所写，也是一种特殊的因果一致性。

3. 会话一致性（Session consistency）：会话一致性将对系统数据的访问过程框定在了一个会话中，系统能保证在同一个有效的会话中实现“读己之所写”的一致性，也就是说，执行更新操作之后，客户端能够在一个会话中始终读取到改数据项的最新值。

4. 单调读一致性（Monotonic read consistency）：读一致性是指如果一个进程从系统中读取出一个数据项的某个值后，那么系统对于该进程后续的任何数据访问都不应该返回更旧的值。

5. 单调写一致性（Monotonic write consistency）：单调写一致性:一个系统需要能够保证来自同一个进程的写操作被顺利的执行。



## 3. 七种解决方案



### 1. 可靠事件队列（最大努力交付）
可靠事件队列也被叫作本地消息表、最大努力一次提交（Best-Effort 1 PC）。它会将最有可能出错的业务以本地事务的方式完成后，采用不断重试的方式来促使同一个分布式事务中的其他关联业务全部完成。若第一个事务（以本地事务方式执行的那个事务）执行失败，整个事务失败回滚即可。但若是第一个事务执行成功了，那么后续也就没有了失败回滚的概念，只许成功，不许失败，若是不断地失败，直至人工介入为止。


下面来谈谈可靠事件队列的执行流程：

- 第一个事务（我们假设第一个事务总是最易出错的）以本地方式执行，失败则回滚；事务成功，为分布式事务中的其他关联事务生成事务消息，并将这些事务消息写入本地消息表（本地消息表存在于第一个事务的本地数据库），这些事务消息记录了事务的执行状态。

- 在系统中建立一个消息服务，定时轮询本地消息表，将事务状态处于“未完成”的消息发送到相应的服务中执行，执行成功则更新本地消息表，失败则重试。这一步可用消息队列实现。

- 事务一直失败，人工介入。



### 2. 事务消息
事务消息是数据最终一致性的解决方案之一，目前对事务消息支持做的最好的 RocketMQ，引一段 RocketMQ 文档描述说说为什么使用事务消息：“消息队列RocketMQ版分布式事务消息不仅可以实现应用之间的解耦，又能保证数据的最终一致性。同时，传统的大事务可以被拆分为小事务，不仅能提升效率，还不会因为某一个关联应用的不可用导致整体回滚，从而最大限度保证核心系统的可用性。在极端情况下，如果关联的某一个应用始终无法处理成功，也只需对当前应用进行补偿或数据订正处理，而无需对整体业务进行回滚。”

**事务消息的三个概念：**

- 事务消息：消息队列RocketMQ版提供类似XA或Open XA的分布式事务功能，通过消息队列RocketMQ版事务消息能达到分布式事务的最终一致。

- 半事务消息：暂不能投递的消息，生产者已经成功地将消息发送到了消息队列RocketMQ版服务端，但是消息队列RocketMQ版服务端未收到生产者对该消息的二次确认，此时该消息被标记成“暂不能投递”状态，处于该种状态下的消息即半事务消息。半事务消息拥有完整的事务信息，只是对消费者不可见。

- 消息回查：由于网络闪断、生产者应用重启等原因，导致某条事务消息的二次确认丢失，消息队列RocketMQ版服务端通过扫描发现某条消息长期处于“半事务消息”时，需要主动向消息生产者询问该消息的最终状态（Commit或是Rollback），该询问过程即消息回查。

RocketMQ 的事务消息解决了是 “先发送信息到 MQ 再执行本地事务” 还是 “先执行本地事务再发送到消息到 MQ “ 的问题，因为这两中执行方式都有可能导致数据的不一致（出错）。

RocketMQ 的解决方法是，在开始执行本地事务之前先给 MQ 发送一个半事务消息，此时这个半事务消息对下一个事务不可见，只有发送半事务消息成功当前事务才能正式执行，否则我们可以选择直接失败或重试等。本地事务执行的结果无论是 Commit 或是 RollBack 都会向 MQ 报告，若 MQ 收到 Commit，则第一步发送的半事务消息将对修改为对消费者可见，若收到 RollBack，则消息将被删除。

通过这种方式保证了本地事务执行和发送消息到 MQ 这两个操作可以作为一个整体的原子操作，因为它保证只有本地事务执行成功下一个事务才能够收到消息。但是在本地事务执行之后 MQ 有可能不能收到 Commit 或 RollBack 通知（可能消息丢失，执行本地事务的程序、机器宕机），所以 RocketMQ 提供了一种消息回查的机制，在一定时间后 MQ 会主动询问本地事务的执行状态，以确保分布式事务能够继续执行下去。

**RocketMQ 事务消息的交互流程**

1. 生产者将半事务消息发送至消息队列RocketMQ版服务端。

2. 消息队列RocketMQ版服务端将消息持久化成功之后，向生产者返回Ack确认消息已经发送成功，此时消息为半事务消息。

3. 生产者开始执行本地事务逻辑。

4. 生产者根据本地事务执行结果向服务端提交二次确认结果（Commit或是Rollback），服务端收到确认结果后处理逻辑如下：

     二次确认结果为Commit：服务端将半事务消息标记为可投递，并投递给消费者。

      二次确认结果为Rollback：服务端将回滚事务，不会将半事务消息投递给消费者。

5. 在断网或者是生产者应用重启的特殊情况下，若服务端未收到发送者提交的二次确认结果，或服务端收到的二次确认结果为Unknown未知状态，经过固定时间后，服务端将对消息生产者即生产者集群中任一生产者实例发起消息回查。

**事务消息回查步骤如下：**

- 生产者收到消息回查后，需要检查对应消息的本地事务执行的最终结果。

- 生产者根据检查得到的本地事务的最终状态再次提交二次确认，服务端仍按照步骤4对半事务消息进行处理。

**事务消息使用上的限制**

若某个事务执行失败，上一个事务将不会被回滚。

事务消息不支持延时消息和批量消息。

事务消息的 Group ID 不能与其他类型消息的 Group ID 共用。与其他类型的消息不同，事务消息有回查机制，回查时消息队列 RocketMQ 版服务端会根据 Group ID 去查询生产者客户端。

为避免单个消息被检查太多次而导致半事务消息堆积，单个消息的检查次数限制为 15 次，但是用户可以通过 Broker 配置文件的TransactionCheckMax参数来修改此限制。如果已经检查某条消息超过 N 次 （N = TransactionCheckMax）则 Broker 将丢弃此消息，并在默认情况下同时打印错误日志。用户可以通过重写AbstractTransactionalMessageCheckListener 类来修改这个行为。

事务消息将在 Broker 配置文件中的参数transactionTimeout这样的特定时间长度之后被检查。当发送事务消息时，用户还可以通过设置用户属性CHECK_IMMUNITY_TIME_IN_SECONDS来改变这个限制，该参数优先于transactionTimeout参数。

### 3. 最大努力通知

最大努力通知事务的主流实现仍是基于 MQ 来进行事务控制。最大努力通知事务和事务消息都是通知型事务，主要适用于那些需要异步更新数据，并且对数据的实时性要求较低的场景。

最大努力通知事务主要是一种对最终一致性的兜底措施，依赖 MQ 确保消息不会丢失且最终被消费。

对于最大努力通知没有多少内容要说的，消息有可能被重复消费，做一下幂等就好了。



### 4. XA 事务
#### 4.1 传统的 XA 事务

XA 的两个重要角色：

- 事务管理器（TM，Transaction Manager），用于协调全局事务，在 Mysql 中连接数据库的客户端作为 TM

- 资源管理器（RM， Resource Manager），用于驱动本地事务，通常一个数据库就是一个 RM

- 上面的两个角色通常都是由数据库来扮演，因此想要使用 XA 事务，使用的数据库必须有对 XA 提供支持。

**两阶段提交（2PC）协议：**

- 准备阶段：又叫作投票阶段，所有的 RM 都执行了自己的本地事务，若执行成功，并在重做日志中记录了全部事务提交操作所要做的内容，此时面对 TM 的询问回复 Prepared 表示事务已经执行成功做好提交的准备了；否则事务执行失败，对 TM 回复 Non-Prepared，表示事务执行失败需要回滚。需要注意的是，在真正提交或回滚之前，本地事务持有的锁都不会释放，维持数据对其他事务内观察者的隔离状态。

- 提交阶段：又叫作执行阶段，TM 如果在上一阶段收到所有的 RM 的回复的 Prepared  消息，则先将自己的本地事务状态 Commit 并持久化，然后向所有 RM 发出 Commit 指令，让 所有的 RM 执行提交操作；否则，任意一个 RM 回复了 Non-Prepared 消息或任意一个 RM 超时未回复，TM 将自己完成事务的状态设为 Abort 并持久化后，向所有 RM 发送 Abort 指令，让所有 RM 立即执行回滚操作。

**XA 能够保证数据一致性的前提条件：**

1. 提交阶段的消息不会。如果准备阶段的消息丢失了，TM 只要超时未能接受到所有 RM 的 Prepared 消息就会执行回滚操作，此时依然能够保证一致性；但若是提交阶段失败了，未收到消息的 RM 将不会执行提交或回滚操作（出现部分提交部分未提交现象），只能等到崩溃的节点重新恢复。

2. 必须假设因为网络分区、机器崩溃或者其他原因而导致失联的节点最终能够恢复，不会永久性地处于失联。由于在准备阶段已经写入了完整的重做日志，所以当失联机器一旦恢复，就能够从日志中找出已准备妥当但未提交的事务日志，进而向 TM 查询该事务的状态，确定下一步应该进行提交还是回滚操作。

**2PC 的缺点：**

- 单点问题：如果因为 TM 宕机而无法正常发出 Commit 或 RollBack 指令，那所有的 RM 都将处于等待状态，也不会释放占有的资源。

- 性能问题：在 2PC 中，所有的 RM 相当于被绑定为一个统一调度的整体，期间要经过两次远程服务调用，三次数据持久化（准备阶段写重做日志，TM 做状态持久化，提交阶段在日志中写入提交记录），整个过程将持续到所有 RM 中最慢的那一个处理操作结束为止，这决定了 2PC 的性能通常都较差。

- 一致性风险：总是要假设网络是稳定的，且数据库系统拥有宕机恢复能力，不然仍会有一致性问题。尽管对于每一个 DBMS 来说宕机恢复能力是必须具备的。

#### 4.2 Seata 对 XA 事务的实现

**Seata 对分布式事务的处理提出的三个角色模型：**

- 事务协调器（TC，Transaction Coordinator）：它是独立的中间件，需要独立部署运行，它维护全局事务的运行状态，接收 TM 指令发起全局事务的提交与回滚，负责与 RM 通信协调各各分支事务的提交或回滚。

- 事务管理器（TM，Transaction Manager）：TM 需要嵌入应用程序中工作，它负责开启一个全局事务，并最终向 TC 发起全局提交或全局回滚的指令。

- 资源管理器（RM，Resource Manager）：控制分支事务，负责分支注册、状态汇报，并接收事务协调器 TC 的指令，驱动分支（本地）事务的提交和回滚。

**Seata 是如何通过这三个角色的交互实现 XA 的？**

在执行阶段（准备阶段）开始之前，TM 需要向 TC 发起开启全局事务的请求，全局事务创建成功并生成一个全局唯一的 XID，接下来进入执行阶段。

RM 向 TC 注册分支事务，该分支事务和全局事务 XID 进行绑定以纳入全局事务的管辖。

XA Start，RM 开始执行 SQL 语句，XA End，汇报事务的执行结果。

完成阶段，TM 向 TC 发起全局提交或全局回滚的指令，TC 驱动 RM 执行提交或回滚。



**Seata 实现的 XA 存在什么问题？**

1. 数据锁定：在分布式事务提交或回滚前，各个 RM 持有的锁资源依然不会被释放。

2. 协议阻塞：XA prepare 后，分支事务进入阻塞阶段，收到 XA commit 或 XA rollback 前必须阻塞等待。在这个阻塞阶段，各个 RM 依然锁定着数据，如果某个 RM 与 TC 失联了，那么将不会收到分支事务结束的命令，数据也将会被一直阻塞。这个问题是 XA 协议的核心痛点，Seata 引入了避免”失联“和增加”自解锁“机制，但这两种机制都是兜底的策略，不代表问题就不存在了。

3. 性能差：性能的损耗主要来自两个方面：一方面，事务协调过程，增加单个事务的执行时间；另一方面，并发事务数据的锁冲突，降低吞吐。



### 5. TCC  事务
TCC 是分布式事务中的二阶段提交协议，它的全称为 Try-Confirm-Cancel，即资源预留（Try）、确认操作（Confirm）、取消操作（Cancel），他们的具体含义如下：

- Try：尝试执行，对业务所需的所有资源（不限于一个 RM）的检查并预留，保障了一致性和隔离性。

- Confirm：确认执行阶段，不做任业务检查，直接利用 Try 阶段准备的资源执行 Commit 操作。只要 Try 阶段成功，Confirm 就一定会执行成功，但是 Confirm 阶段可能会被重复执行。

- Cancel：对业务处理进行取消，即回滚操作，释放Try 预留的资源。可能会被重复执行。

- TCC 是一种侵入式的分布式事务解决方案，以上三个操作都需要业务系统自行实现，对业务系统有着非常大的入侵性，设计相对复杂，但优点是 TCC 完全不依赖数据库，能够实现跨数据库、跨应用资源管理，对这些不同数据访问通过侵入式的编码方式实现一个原子操作，更好地解决了在各种复杂业务场景下的分布式事务问题。

#### 5.1 Seata 对 TCC 的实现

Seata 对 TCC 的实现依然是满足 4.2 中的三角色模型。Seata 是如何利用三角色来实现 TCC 的可以归纳为资源解析、资源管理、事务处理。

资源解析就是把 TCC 接口进行解析并注册。在 Seata 启动时，会存在一个叫GlobalTransactionalScanner的注解进行扫描找到已被 TCC 代理的 Bean。因为一个 TCC 接口可以是 RPC（调用方），也可以是 JVM 内部调用（发起方，开启分布式事务的发起方将成为 TM），所以对一个已经被 TCC 代理 Bean 会先判断其是否是一个 Remoting Bean，如果是则需要调用getServiceDesc方法对该 Bean 做进一步的解析，并将解析后的 remotingBeanDesc 放入本地缓存remotingServiceMap中，同时调用解析类RemotingParse.isService方法判断该 Bean 是否是一个发起方，如果是一个发起方则解析TwoPhaseBusinessAction注解的内容生成一个TCCResource并向 TC 注册，每个TCCResource都有一个资源 ID。如果 TCC 接口是一个调用方，Seata 总会拦截 TCC 接口的调用，在每次调用 Try 方法前，先向 TC 注册一个分支事务，然后才去执行原来的 RPC 调用。

TCC 的资源是TCCResource，一个 TCC 接口当成就是一个TCCResource，它的一个重要属性 resourceId 其实就是@TwoPhaseBusinessAction的 name。对于发起方 Seata 在启动时机会被注册到 TC，并在本地tccResourceCache中缓存，tccResourceCache是一个ConcurrentHashMap结构，同时通过RmRpcClient将该TCCResource的resourceId、address等信息注册到服务端，便于后续TC通过RPC回调到正确的地址。对于调用方，TCCResource最终也会被注册到 TC，在其他服务中调用方将成为发起方从而将TCCResource注册到  TC。

当 TM 决议二阶段提交时，TC 会通过分支注册的资源 ID 回调到对应的参与者（即分支事务绑定的 TCC 接口发起方）服务中执行TCCResource的 Confirm/Cancel 方法。

资源管理器中会根据 resourceId 在本地缓存找到对应的 TCCResource，同时根据 xid、branchId、resourceId、applicationData 找到对应的BusinessActionContext上下文，执行的参数（执行参数在注册分支事务时就已经被传到 TC 中保存）就在上下文中。最后，执行TCCResource 中获取 commit 的方法进行二阶段提交。二阶段回滚同理类似。

TCC 的特点是事务隔离性较好，且在实现上不依赖于数据库是否支持分布式事务，完全在用户代码层面进行解决。但是 TCC 对代码的侵入性较强，往往也带来了更高的开发成本，同时使用 TCC 也需要注意空回滚、幂等和悬挂三个问题。

#### 5.2 空回滚的处理

简单来说，空回滚就是在 Try 执行之前 Cancel 已经先一步执行了。可能的原因是某一个服务宕机或网络异常，在全局事务开启后，对该异常服务调用了 Try，但由于未能得到 ok 响应，全局事务认为应该执行 Cancel 以推动事务到达终态，从而导致 Cancel 的执行在 Try 之前。

那么要做到防止空回滚就得在执行 Cancel 之前断定 Try 已经执行了。Seata 的做法是，在 TC 中维护了一个事务控制表，里面包含了事务得 XID 和 BranchID 信息，在 Try 执行时插入一条记录表示 Try 执行了，在 Cancel 执行时要先读取这条记录，若记录不存在，Cancel 方法拒绝执行。

#### 5.3 幂等

TCC 事务的 Confirm/Cancel 都有被重复执行的可能，那么就需要保证 Confirm/Cancel 不管是执行一次还是多次最终的结果都是一致的，也就是保证资源不会被重复释放。Seata 对幂等的处理是在 TC 维护的事务控制表中记录了一个 status 字段，该字段有三个值tried:1、committed:2和rollbacked:3。

Confirm/Cancel 方法执行之后，会将状态改为 committed 或 rollbacked 状态，当重复调用 Confirm/Cancel 方法时，对 status 字段的状态进行判断即可解决幂等问题。

#### 5.4 悬挂的处理

悬挂是指在 Try 在调用后因为网络堵塞而延时到达，但是 Seata 全局事务已经超时并发起回滚执行 Cancel 方法，由于 Seata 允许空回滚的，所以此时 Cancel 方法是被允许执行的，尽管 Cancel 方法在空回滚下并不会真正执行。在 Cancel 方法执行完成后 Try 方法姗姗来迟并执行，这就会导致 Try 执行锁定的预留资源永远无法提交和释放。

Seata 的解决方案是为 status 字段增加一个状态：suspended:4。如果发现事务控制表有相关的记录，说明 Cancel 方法已经先 Try 方法执行了，因此 TC 在判断发现 status = 4 时会阻止 Try 方法执行。

#### 6. SAGA 事务

附上Seata 官方文档对SAGA 的讲解与实现方式：https://seata.io/zh-cn/blog/seata-at-tcc-saga.html

## 7. AT 事务

AT 模式是一种无侵入的分布式事务解决方案。在 AT 模式下，用户只需关注自己的“业务 SQL”，用户的 “业务 SQL” 作为一阶段，Seata 框架会自动生成事务的二阶段提交和回滚操作。

**AT 模式如何做到对业务的无侵入 ：**

- 一阶段：Seata 会拦截“业务 SQL”，首先解析 SQL 语义，找到“业务 SQL”要更新的业务数据，在业务数据被更新前，将其保存成“before image”，然后执行“业务 SQL”更新业务数据，在业务数据更新之后，再将其保存成“after image”，最后生成行锁。以上操作全部在一个数据库事务内完成，这样保证了一阶段操作的原子性。

- 二阶段提交：二阶段如果是提交的话，因为“业务 SQL”在一阶段已经提交至数据库， 所以 Seata 框架只需将一阶段保存的快照数据和行锁删掉，完成数据清理即可。

- 二阶段回滚：二阶段如果是回滚的话，Seata 就需要回滚一阶段已经执行的“业务 SQL”，还原业务数据。回滚方式便是用“before image”还原业务数据；但在还原前要首先要校验脏写，对比“数据库当前业务数据”和 “after image”，如果两份数据完全一致就说明没有脏写，可以还原业务数据，如果不一致就说明有脏写，出现脏写就需要转人工处理。

AT 模式的一阶段、二阶段提交和回滚均由 Seata 框架自动生成，用户只需编写“业务 SQL”，便能轻松接入分布式事务，AT 模式是一种对业务无任何侵入的分布式事务解决方案。

关于 Seata 的 AT 模式下的全局锁、脏读、藏写等问题，请转到链接 [详解 Seata AT 模式事务隔离级别与全局锁设计](https://seata.io/zh-cn/blog/seata-at-lock.html) 继续阅读。




​